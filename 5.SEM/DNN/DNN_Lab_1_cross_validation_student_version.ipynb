{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ],
      "metadata": {
        "id": "Jrz1Kic6-keH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMeI3m9u-ZBN"
      },
      "source": [
        "# Validation and cross-validation\n",
        "\n",
        "In this exercise you will implement a validation pipeline.\n",
        "\n",
        "At the end of the MSLE exercise you tested your model against the training and test datasets. As you should observe, there's a gap between the results. By validating your model, not only should you be able to anticipate the test time performance, but also have a method to compare different models.\n",
        "\n",
        "Implement the basic validation method, i.e. a random split. Test it with your model from Exercise MSLE."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "!wget -O mieszkania.csv https://www.dropbox.com/s/zey0gx91pna8irj/mieszkania.csv?dl=1\n",
        "!wget -O mieszkania_test.csv https://www.dropbox.com/s/dbrj6sbxb4ayqjz/mieszkania_test.csv?dl=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMxpoCCqXXWZ",
        "outputId": "8651e082-2cfc-45c8-c3fa-b8fb14c6ac58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-26 14:43:50--  https://www.dropbox.com/s/zey0gx91pna8irj/mieszkania.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.18, 2620:100:601f:18::a27d:912\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/zey0gx91pna8irj/mieszkania.csv [following]\n",
            "--2023-10-26 14:43:51--  https://www.dropbox.com/s/dl/zey0gx91pna8irj/mieszkania.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com/cd/0/get/CGU4zr5W253GsKqIPs0BEKOT5j2FLc3XHqieQVBg7nxuomJlZU2xMTMoR8cx8KUZZQV-RWIScCO0H540ToSYwdXr-vwc5YUDtSx7IjnHpZ_C0Hg0zrUEknShmNfFJmpTHWs/file?dl=1# [following]\n",
            "--2023-10-26 14:43:52--  https://uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com/cd/0/get/CGU4zr5W253GsKqIPs0BEKOT5j2FLc3XHqieQVBg7nxuomJlZU2xMTMoR8cx8KUZZQV-RWIScCO0H540ToSYwdXr-vwc5YUDtSx7IjnHpZ_C0Hg0zrUEknShmNfFJmpTHWs/file?dl=1\n",
            "Resolving uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com (uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com (uc3e4390aab5f5133bbf7a69a7c2.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6211 (6.1K) [application/binary]\n",
            "Saving to: ‘mieszkania.csv’\n",
            "\n",
            "mieszkania.csv      100%[===================>]   6.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-26 14:43:52 (1.82 GB/s) - ‘mieszkania.csv’ saved [6211/6211]\n",
            "\n",
            "--2023-10-26 14:43:52--  https://www.dropbox.com/s/dbrj6sbxb4ayqjz/mieszkania_test.csv?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601f:18::a27d:912\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/dl/dbrj6sbxb4ayqjz/mieszkania_test.csv [following]\n",
            "--2023-10-26 14:43:53--  https://www.dropbox.com/s/dl/dbrj6sbxb4ayqjz/mieszkania_test.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com/cd/0/get/CGXRNDxjV_ZnHA4E7UeteYmBi3Zahk9Mj6zxJm7qOu8aflnRDvYPfgQ6sL7ePcvaJ69xuO6rIRi5jK9Ydj8Za3iyLdNfFN_28MX27aXk8dp4wFI7cu66U3D_pMp9Y2ZAcJU/file?dl=1# [following]\n",
            "--2023-10-26 14:43:54--  https://uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com/cd/0/get/CGXRNDxjV_ZnHA4E7UeteYmBi3Zahk9Mj6zxJm7qOu8aflnRDvYPfgQ6sL7ePcvaJ69xuO6rIRi5jK9Ydj8Za3iyLdNfFN_28MX27aXk8dp4wFI7cu66U3D_pMp9Y2ZAcJU/file?dl=1\n",
            "Resolving uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com (uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com (uc9c1ab44e95e295ac981a2a7cf7.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6247 (6.1K) [application/binary]\n",
            "Saving to: ‘mieszkania_test.csv’\n",
            "\n",
            "mieszkania_test.csv 100%[===================>]   6.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-26 14:43:54 (2.46 GB/s) - ‘mieszkania_test.csv’ saved [6247/6247]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple"
      ],
      "metadata": {
        "id": "Uw4R7L0acz8e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load2(name: str) -> Tuple[np.ndarray, np.array, np.ndarray]:\n",
        "    data = pd.read_csv(name)\n",
        "    x = data.loc[:, ((data.columns != 'cena') & (data.columns != 'dzielnica'))]\n",
        "    dum = data['dzielnica']\n",
        "    dum = pd.get_dummies(dum)\n",
        "    x = pd.concat([x, dum], axis=1)\n",
        "    y = data['cena']\n",
        "\n",
        "    return x.to_numpy().astype(float), y.to_numpy().astype(float)"
      ],
      "metadata": {
        "id": "MNjo9j9EXD84"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = load2('mieszkania.csv')\n",
        "x_test, y_test = load2('mieszkania_test.csv')"
      ],
      "metadata": {
        "id": "uoYy1AU5XD_e"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MSLEModel:\n",
        "    def __init__(self):\n",
        "        self.weights = []\n",
        "        self.bias = 0\n",
        "\n",
        "    def msle(self, ys, ps):\n",
        "      assert len(ys) == len(ps)\n",
        "      return np.mean((np.log(1 + ys) - np.log(1 + ps)) ** 2)\n",
        "\n",
        "    def predict(self, xs):\n",
        "      return xs @ self.weights + self.bias\n",
        "\n",
        "    def evaluate(self, xs, ys):\n",
        "        ps = self.predict(self.weights, self.bias, xs)\n",
        "        return self.msle(ys, ps)\n",
        "\n",
        "    def fit(self, xs, ys):\n",
        "        n_epochs = 400000\n",
        "        step_size = 1e4\n",
        "        b, f = xs.shape\n",
        "        self.weights = np.random.uniform(low=-1 / np.sqrt(f), high=1 / np.sqrt(f), size=[f])\n",
        "        self.bias = (np.exp(np.mean(np.log(1 + ys))) - 1)\n",
        "        for i in range(n_epochs):\n",
        "          prediction = self.predict(xs)\n",
        "          grad_help = 2 * (np.log(prediction + 1) - np.log(ys + 1)) / (1 + prediction)\n",
        "          grad_bias = np.mean(grad_help)\n",
        "          grad_weights = (1 / b) * xs.T @ grad_help\n",
        "          self.weights -= step_size * grad_weights\n",
        "          self.bias -= step_size * grad_bias\n"
      ],
      "metadata": {
        "id": "KzqR160oeMTT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0nRHYL-ZBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1af49e-0615-4d27-9c9b-657f29bcfdbf"
      },
      "source": [
        "#######################################################\n",
        "# TODO: Implement the basic validation method,        #\n",
        "# compare MSLE on training, validation, and test sets #\n",
        "#######################################################\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train = x_train.astype(np.float64)\n",
        "x_test = x_test.astype(np.float64)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
        "\n",
        "model = MSLEModel()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(x_train)\n",
        "y_val_pred = model.predict(x_val)\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Calculate MSLE for each set.\n",
        "train_msle = model.msle(y_train, y_train_pred)\n",
        "val_msle = model.msle(y_val, y_val_pred)\n",
        "test_msle = model.msle(y_test, y_test_pred)\n",
        "print(f\"MSLE on training set: {train_msle}\")\n",
        "print(f\"MSLE on validation set: {val_msle}\")\n",
        "print(f\"MSLE on test set: {test_msle}\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSLE on training set: 0.050334035793693506\n",
            "MSLE on validation set: 0.05931517615205444\n",
            "MSLE on test set: 0.07810061688825645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnf-KvC-ZBW"
      },
      "source": [
        "To make the random split validation reliable, a huge chunk of training data may be needed. To get over this problem, one may apply cross-validaiton.\n",
        "\n",
        "![alt-text](https://chrisjmccormick.files.wordpress.com/2013/07/10_fold_cv.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbu4F_h9-ZBX"
      },
      "source": [
        "Let's now implement the method. Make sure that:\n",
        "* number of partitions is a parameter,\n",
        "* the method is not limited to `mieszkania.csv`,\n",
        "* the method is not limited to one specific model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbfmYPOh-ZBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222a87ce-63c7-430c-aaeb-eb763997c605"
      },
      "source": [
        "####################################\n",
        "# TODO: Implement cross-validation #\n",
        "####################################\n",
        "def cross_validation(partitions, x_train, y_train, model):\n",
        "    samples = len(x_train)\n",
        "    partition_size = samples // partitions\n",
        "    results = np.zeros(partitions)\n",
        "\n",
        "    for i in range(partitions):\n",
        "        start = i * partition_size\n",
        "        end = samples if i == partitions - 1 else (i + 1) * partition_size\n",
        "        x_train_part = np.concatenate((x_train[:start], x_train[end:]), axis=0)\n",
        "        y_train_part = np.concatenate((y_train[:start], y_train[end:]))\n",
        "        x_val_part = x_train[start:end]\n",
        "        y_val_part = y_train[start:end]\n",
        "\n",
        "        model.fit(x_train_part, y_train_part)\n",
        "        y_val_pred = model.predict(x_val_part)\n",
        "\n",
        "        error = model.msle(y_val_part, y_val_pred)\n",
        "        results[i] = error\n",
        "\n",
        "    return results.mean()\n",
        "\n",
        "\n",
        "model = MSLEModel()\n",
        "print(cross_validation(2, x_train, y_train, model))\n",
        "print(cross_validation(5, x_train, y_train, model))\n",
        "print(cross_validation(10, x_train, y_train, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.053054070360327554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF2-UXXR-ZBc"
      },
      "source": [
        "Recall that sometimes validation may be tricky, e.g. significant class imbalance, having a small number of subjects, geographically clustered instances...\n",
        "\n",
        "What could in theory go wrong here with random, unstratified partitions? Think about potential solutions and investigate the data in order to check whether these problems arise here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-y3kUy-ZBe"
      },
      "source": [
        "##############################\n",
        "# TODO: Investigate the data #\n",
        "##############################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}