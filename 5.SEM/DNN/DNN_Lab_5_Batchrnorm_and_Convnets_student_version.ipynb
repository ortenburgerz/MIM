{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfdcY0Vq6e80"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
    "\n",
    "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
    "<hr>\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
    "\n",
    "<center>\n",
    "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
    "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
    "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
    "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcTwzhX8fBqs"
   },
   "source": [
    "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "This exercise covers two aspects:\n",
    "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch.\n",
    "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
    "\n",
    "\n",
    "Tasks:\n",
    "1. Check that the given implementation reaches 95% test accuracy for\n",
    "   architecture input-64-64-10 in a few thousand batches.\n",
    "2. Improve initialization and check that the network learns much faster\n",
    "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.\n",
    "3. Check, that with proper initialization we can train architecture\n",
    "   input-64-64-64-64-64-10, while with bad initialization it does\n",
    "   not even get off the ground.\n",
    "4. Add dropout implemented in pytorch (but without using torch.nn.Dropout)\n",
    "5. Check that with 10 hidden layers (64 units each) even with proper\n",
    "    initialization the network has a hard time to start learning.\n",
    "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
    "    * compute batch mean and variance\n",
    "    * add new variables beta and gamma\n",
    "    * check that the networks learns much faster for 5 layers\n",
    "    * check that the network learns even for 10 hidden layers.\n",
    "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvAaf5LrqlbR"
   },
   "source": [
    "1. Check that the given implementation reaches 95% test accuracy for\n",
    "   architecture input-64-64-10 in a few thousand batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IYAsziKffBFV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DMtap4QCfBH8"
   },
   "outputs": [],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.normal_(mean=0,std=0.25)\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = x.matmul(self.weight.t())\n",
    "        r += self.bias\n",
    "        return r\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = Linear(784, 64)\n",
    "        self.fc2 = Linear(64, 64)\n",
    "        self.fc3 = Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WgfUP23AfBMd"
   },
   "outputs": [],
   "source": [
    "class MnistTrainer(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self):\n",
    "        net = Net()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "        for epoch in range(20):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ezvIQbgsfBRT",
    "outputId": "835fca7c-21a4-4eca-b182-c068a7f59659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 85079145.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 28040669.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 28694263.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 13491875.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "[1,   100] loss: 1.156\n",
      "[1,   200] loss: 0.363\n",
      "[1,   300] loss: 0.294\n",
      "[1,   400] loss: 0.259\n",
      "Accuracy of the network on the 10000 test images: 93.6 %\n",
      "[2,   100] loss: 0.212\n",
      "[2,   200] loss: 0.182\n",
      "[2,   300] loss: 0.192\n",
      "[2,   400] loss: 0.180\n",
      "Accuracy of the network on the 10000 test images: 94.51 %\n",
      "[3,   100] loss: 0.152\n",
      "[3,   200] loss: 0.145\n",
      "[3,   300] loss: 0.153\n",
      "[3,   400] loss: 0.151\n",
      "Accuracy of the network on the 10000 test images: 95.56 %\n",
      "[4,   100] loss: 0.113\n",
      "[4,   200] loss: 0.120\n",
      "[4,   300] loss: 0.126\n",
      "[4,   400] loss: 0.131\n",
      "Accuracy of the network on the 10000 test images: 96.0 %\n",
      "[5,   100] loss: 0.111\n",
      "[5,   200] loss: 0.110\n",
      "[5,   300] loss: 0.110\n",
      "[5,   400] loss: 0.108\n",
      "Accuracy of the network on the 10000 test images: 95.94 %\n",
      "[6,   100] loss: 0.097\n",
      "[6,   200] loss: 0.095\n",
      "[6,   300] loss: 0.092\n",
      "[6,   400] loss: 0.098\n",
      "Accuracy of the network on the 10000 test images: 95.9 %\n",
      "[7,   100] loss: 0.082\n",
      "[7,   200] loss: 0.085\n",
      "[7,   300] loss: 0.100\n",
      "[7,   400] loss: 0.095\n",
      "Accuracy of the network on the 10000 test images: 96.4 %\n",
      "[8,   100] loss: 0.075\n",
      "[8,   200] loss: 0.082\n",
      "[8,   300] loss: 0.084\n",
      "[8,   400] loss: 0.085\n",
      "Accuracy of the network on the 10000 test images: 96.41 %\n",
      "[9,   100] loss: 0.069\n",
      "[9,   200] loss: 0.078\n",
      "[9,   300] loss: 0.075\n",
      "[9,   400] loss: 0.082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ad0141ea3361>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-fc0ef9d6a23d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_put_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mworker_queue_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mnotify\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;31m# gh-92530: The previous call of notify() released the lock,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = MnistTrainer(batch_size=128)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTn4WTjyq6ed"
   },
   "source": [
    "2. Improve initialization and check that the network learns much faster\n",
    "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "id": "uHnsDHHvt3OD",
    "outputId": "dd7ab2ac-4594-4965-af4a-17349e86802a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.711\n",
      "[1,   200] loss: 0.276\n",
      "[1,   300] loss: 0.224\n",
      "[1,   400] loss: 0.191\n",
      "Accuracy of the network on the 10000 test images: 95.5 %\n",
      "[2,   100] loss: 0.136\n",
      "[2,   200] loss: 0.137\n",
      "[2,   300] loss: 0.136\n",
      "[2,   400] loss: 0.133\n",
      "Accuracy of the network on the 10000 test images: 96.78 %\n",
      "[3,   100] loss: 0.098\n",
      "[3,   200] loss: 0.098\n",
      "[3,   300] loss: 0.101\n",
      "[3,   400] loss: 0.092\n",
      "Accuracy of the network on the 10000 test images: 97.0 %\n",
      "[4,   100] loss: 0.078\n",
      "[4,   200] loss: 0.074\n",
      "[4,   300] loss: 0.078\n",
      "[4,   400] loss: 0.076\n",
      "Accuracy of the network on the 10000 test images: 97.11 %\n",
      "[5,   100] loss: 0.059\n",
      "[5,   200] loss: 0.060\n",
      "[5,   300] loss: 0.069\n",
      "[5,   400] loss: 0.063\n",
      "Accuracy of the network on the 10000 test images: 97.4 %\n",
      "[6,   100] loss: 0.056\n",
      "[6,   200] loss: 0.053\n",
      "[6,   300] loss: 0.054\n",
      "[6,   400] loss: 0.063\n",
      "[7,   100] loss: 0.042\n",
      "[7,   200] loss: 0.042\n",
      "[7,   300] loss: 0.050\n",
      "[7,   400] loss: 0.049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee93f98e7351>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mtrainer2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMnistTrainer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrainer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-ee93f98e7351>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Linear2(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear2, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = x.matmul(self.weight.t())\n",
    "        r += self.bias\n",
    "        return r\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = Linear2(784, 64)\n",
    "        self.fc2 = Linear2(64, 64)\n",
    "        self.fc3 = Linear2(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class MnistTrainer2(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self):\n",
    "        net = Net2()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "        for epoch in range(20):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))\n",
    "\n",
    "trainer2= MnistTrainer2(batch_size=128)\n",
    "trainer2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6yykTXEt2Ns"
   },
   "source": [
    "3. Check, that with proper initialization we can train architecture\n",
    "   input-64-64-64-64-64-10, while with bad initialization it does\n",
    "   not even get off the ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGQerfDnqtMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULTQ3i-zw-NJ"
   },
   "source": [
    "\n",
    "4. Add dropout implemented in pytorch (but without using torch.nn.Dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQMSSwuifBTo",
    "outputId": "1991d95d-4221-4516-8a8f-1c2826b12ac8"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.346\n",
      "[1,   200] loss: 0.776\n",
      "[1,   300] loss: 0.673\n",
      "[1,   400] loss: 0.617\n",
      "Accuracy of the network on the 10000 test images: 92.03 %\n",
      "[2,   100] loss: 0.568\n",
      "[2,   200] loss: 0.549\n",
      "[2,   300] loss: 0.527\n",
      "[2,   400] loss: 0.508\n",
      "Accuracy of the network on the 10000 test images: 92.46 %\n",
      "[3,   100] loss: 0.467\n",
      "[3,   200] loss: 0.467\n",
      "[3,   300] loss: 0.487\n",
      "[3,   400] loss: 0.464\n",
      "Accuracy of the network on the 10000 test images: 93.53 %\n",
      "[4,   100] loss: 0.458\n",
      "[4,   200] loss: 0.455\n",
      "[4,   300] loss: 0.459\n",
      "[4,   400] loss: 0.451\n",
      "Accuracy of the network on the 10000 test images: 93.98 %\n",
      "[5,   100] loss: 0.435\n",
      "[5,   200] loss: 0.416\n",
      "[5,   300] loss: 0.437\n",
      "[5,   400] loss: 0.431\n",
      "Accuracy of the network on the 10000 test images: 93.83 %\n",
      "[6,   100] loss: 0.404\n",
      "[6,   200] loss: 0.424\n",
      "[6,   300] loss: 0.395\n",
      "[6,   400] loss: 0.408\n",
      "Accuracy of the network on the 10000 test images: 94.74 %\n",
      "[7,   100] loss: 0.390\n",
      "[7,   200] loss: 0.400\n",
      "[7,   300] loss: 0.411\n",
      "[7,   400] loss: 0.395\n",
      "Accuracy of the network on the 10000 test images: 94.8 %\n",
      "[8,   100] loss: 0.382\n",
      "[8,   200] loss: 0.380\n",
      "[8,   300] loss: 0.394\n",
      "[8,   400] loss: 0.397\n",
      "Accuracy of the network on the 10000 test images: 94.66 %\n",
      "[9,   100] loss: 0.384\n",
      "[9,   200] loss: 0.393\n",
      "[9,   300] loss: 0.377\n",
      "[9,   400] loss: 0.396\n",
      "Accuracy of the network on the 10000 test images: 94.55 %\n",
      "[10,   100] loss: 0.368\n",
      "[10,   200] loss: 0.376\n",
      "[10,   300] loss: 0.368\n",
      "[10,   400] loss: 0.377\n",
      "Accuracy of the network on the 10000 test images: 95.16 %\n",
      "[11,   100] loss: 0.374\n",
      "[11,   200] loss: 0.357\n",
      "[11,   300] loss: 0.362\n",
      "[11,   400] loss: 0.378\n",
      "Accuracy of the network on the 10000 test images: 95.59 %\n",
      "[12,   100] loss: 0.357\n",
      "[12,   200] loss: 0.363\n",
      "[12,   300] loss: 0.356\n",
      "[12,   400] loss: 0.361\n",
      "Accuracy of the network on the 10000 test images: 95.09 %\n",
      "[13,   100] loss: 0.352\n",
      "[13,   200] loss: 0.363\n",
      "[13,   300] loss: 0.362\n",
      "[13,   400] loss: 0.355\n",
      "Accuracy of the network on the 10000 test images: 95.12 %\n",
      "[14,   100] loss: 0.355\n",
      "[14,   200] loss: 0.346\n",
      "[14,   300] loss: 0.356\n",
      "[14,   400] loss: 0.351\n",
      "Accuracy of the network on the 10000 test images: 95.31 %\n",
      "[15,   100] loss: 0.345\n",
      "[15,   200] loss: 0.358\n",
      "[15,   300] loss: 0.356\n",
      "[15,   400] loss: 0.346\n",
      "Accuracy of the network on the 10000 test images: 95.4 %\n",
      "[16,   100] loss: 0.346\n",
      "[16,   200] loss: 0.361\n",
      "[16,   300] loss: 0.338\n",
      "[16,   400] loss: 0.339\n",
      "Accuracy of the network on the 10000 test images: 95.69 %\n",
      "[17,   100] loss: 0.326\n",
      "[17,   200] loss: 0.342\n",
      "[17,   300] loss: 0.348\n",
      "[17,   400] loss: 0.347\n",
      "Accuracy of the network on the 10000 test images: 95.49 %\n",
      "[18,   100] loss: 0.324\n",
      "[18,   200] loss: 0.331\n",
      "[18,   300] loss: 0.337\n",
      "[18,   400] loss: 0.346\n",
      "Accuracy of the network on the 10000 test images: 95.23 %\n",
      "[19,   100] loss: 0.345\n",
      "[19,   200] loss: 0.334\n",
      "[19,   300] loss: 0.344\n",
      "[19,   400] loss: 0.331\n",
      "Accuracy of the network on the 10000 test images: 95.5 %\n",
      "[20,   100] loss: 0.328\n",
      "[20,   200] loss: 0.334\n",
      "[20,   300] loss: 0.332\n",
      "[20,   400] loss: 0.342\n",
      "Accuracy of the network on the 10000 test images: 95.31 %\n"
     ]
    }
   ],
   "source": [
    "class Linear4(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear4, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = x.matmul(self.weight.t())\n",
    "        r += self.bias\n",
    "        return r\n",
    "\n",
    "\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        self.fc1 = Linear2(784, 64)\n",
    "        self.fc2 = Linear2(64, 64)\n",
    "        self.fc3 = Linear2(64, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class MnistTrainer4(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self):\n",
    "        net = Net4()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "        for epoch in range(20):\n",
    "            net.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))\n",
    "\n",
    "trainer4 = MnistTrainer4(batch_size=128)\n",
    "trainer4.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74fzn-6QxATz"
   },
   "source": [
    "5. Check that with 10 hidden layers (64 units each) even with proper\n",
    "    initialization the network has a hard time to start learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX_2rCycfBWU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojiEl9dYxDty"
   },
   "source": [
    "\n",
    "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
    "    * compute batch mean and variance\n",
    "    * add new variables beta and gamma\n",
    "    * check that the networks learns much faster for 5 layers\n",
    "    * check that the network learns even for 10 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bO4y33Zy3_0e"
   },
   "outputs": [],
   "source": [
    "class Linear6(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Linear6, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "        init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = x.matmul(self.weight.t())\n",
    "        r += self.bias\n",
    "        return r\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super(BatchNorm, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.gamma = Parameter(torch.Tensor(out_features))\n",
    "        self.beta = Parameter(torch.Tensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.ones_(self.gamma)\n",
    "        init.zeros_(self.beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute mean and variance along the features dimension\n",
    "        Ex = torch.mean(x, dim=1, keepdim=True)\n",
    "        Varx = torch.var(x, dim=1, unbiased=False, keepdim=True)\n",
    "\n",
    "        eps = 1e-5\n",
    "        y = (x - Ex) / torch.sqrt(Varx + eps) * self.gamma + self.beta\n",
    "\n",
    "        return y\n",
    "class Net6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net6, self).__init__()\n",
    "        self.fc1 = Linear6(784, 64)\n",
    "        self.fc2 = Linear6(64, 64)\n",
    "        self.fc3 = Linear6(64, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class MnistTrainer6(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose(\n",
    "                [transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self):\n",
    "        net = Net6()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "        for epoch in range(20):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))\n",
    "\n",
    "trainer6 = MnistTrainer6(batch_size=128)\n",
    "trainer6.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3Qal9ae4AOh"
   },
   "source": [
    "\n",
    "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5B1uc4S4A8E"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # Flatten the output for fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MnistConvTrainer(object):\n",
    "    def __init__(self, batch_size):\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.trainset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transform)\n",
    "        self.trainloader = torch.utils.data.DataLoader(\n",
    "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "        self.testset = torchvision.datasets.MNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True, transform=transform)\n",
    "        self.testloader = torch.utils.data.DataLoader(\n",
    "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "    def train(self):\n",
    "        net = ConvNet()\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "        for epoch in range(5):  # Adjust the number of epochs as needed\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in self.testloader:\n",
    "                    images, labels = data\n",
    "                    outputs = net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "                total, 100 * correct / total))\n",
    "\n",
    "trainerconv = MnistConvTrainer(batch_size=128)\n",
    "trainerconv.train()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
